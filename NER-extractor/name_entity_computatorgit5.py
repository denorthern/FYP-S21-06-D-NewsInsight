# -*- coding: utf-8 -*-
"""Name_Entity_ComputatorGIT5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1eK_0ZYnWjuPoWXNYFWvRtwNSjHy3_RJj
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install spacy-transformers
!python -m spacy download en_core_web_trf

from datetime import timedelta, date,datetime
import os

import spacy
nlp = spacy.load("en_core_web_trf")



import pandas as pd 
import threading
import re, string, unicodedata
import nltk
nltk.download('averaged_perceptron_tagger')
import pandas as pd
nltk.download('punkt')
nltk.download('wordnet')
import inflect
from nltk import word_tokenize, sent_tokenize
from nltk.tokenize import word_tokenize
import re
import os
import glob
from nltk.tokenize import word_tokenize

from spacy import displacy
from collections import Counter

import glob
from google.colab import drive
drive.mount('/content/drive')

import time
class NameEntityComputer:
    def daterange(self,start_date, end_date):    # to generate dates  between start date and end date 
     self.start_date=start_date
     self.end_date=end_date 
     for n in range(int ((end_date - start_date).days)):
       yield start_date + timedelta(n)

    def remove_whitespace(self,text):   # extra spaces 
      self.text=text
      return  " ".join(text.split())

    def helper(self, nsite,start_date,end_date,):    #read soyrce and split text into article, source , title etc and preprocess article and find ners
        self.nsite = nsite
        path='/content/'+nsite+'-byDate'
        #dates_folders = os.listdir(path)
        #print(len(dates_folders))
        #print("dates folders ",dates_folders)

        #for j in range(len(dates_folders)):
        for single_date in self.daterange(start_date, end_date):
          print("dates folders ",single_date)
          path2='/content/'+nsite+'-byDate/'+str(single_date)
          #print('/////////////////',path2)
          myFilesPaths =os.listdir(path2)   #extratct all links of file from target folder
          print(len(myFilesPaths))
          #print("inside dates folders ",myFilesPaths)
          listners=[]
          listcategory=[]
          listlink=[]
          listsource=[]
          listdate=[]
          for i in range(len(myFilesPaths)):
               
               Article="0"
               aa=path2+'/'+myFilesPaths[i]
               f = open(aa, "r")
               for x in f:
                     if (x.find('Source:') != -1):  # for extracting source from txt file
                         x1 = x.split("Source:")
                         Source=x1[1:]
                         Source= ''.join([str(elem) for elem in Source]) 
                         Source=Source.strip()                         
                     if (x.find('Link:') != -1):   # for extracting link from txt file
                         x1 = x.split("Link:")
                         Link=x1[1:]
                         Link= ''.join([str(elem) for elem in Link]) 
                         Link=Link.strip()

                     if (x.find('DateOfExtraction:') != -1):   # for extracting date of extraction from txt file
                         pass

                     if (x.find('DateOfPublication:') != -1):   # for extracting date of publication from txt file
                         pass

                     if (x.find('Title:') != -1):  # for extracting title from txt file
                         x1 = x.split("Title:")
                         Title=x1[1:]
                         Title= ''.join([str(elem) for elem in Title])
                     if (x.find('Author:') != -1):  # for extracting author from txt file
                         pass
          
                     else:         
                       #x1 = x.split(":")    # for extracting article from txt file
                         pArticle=x
                         Article=Article + pArticle 

               x1 = Article.split("Article:")
               Article=x1[1:]
               Article = ''.join([str(elem) for elem in Article])
               Article = re.sub('[;:!@#$"%^&*()+_=<>/?{}~`|]', '', Article)
               Article = ''.join([str(elem) for elem in Article])         
               #print('===>',Article)  #debugging     
               Article=Article+Title   # to add ners of title we merge title and article
              #  print('6666666666',Article)
              #  #Article = ' '.join([str(elem) for elem in Article])
               Article=re.sub(r'http\S+', '', Article)  # to remove http links if exist
               Article = ''.join([str(elem) for elem in Article])
              #  print('7777777777',Article)
              #  Article=re.sub(r'[^\w]', ' ', Article)   # keep alpha numeric values will match anything that's not alphanumeric or underscore
              # Article = ''.join([str(elem) for elem in Article])  # list to string
               #print('88888888888888888',Article)
              # Article=self.remove_whitespace(Article)
              # Article = ''.join([str(elem) for elem in Article])
               doc = nlp(Article)
               included_labels = ("PERSON","ORG", "EVENT","NORP","GPE" ,"PRODUCT","LANGUAGE","LAW","WORK_OF_ART","LOC","FACILITY")  # keep only these ners we do not need time etc ners
               DesiredNER = [ent for ent in doc.ents if ent.label_  in included_labels]
               DesiredCategory = [ent.label_ for ent in doc.ents if ent.label_  in included_labels]
               ner0=DesiredNER  
               category0=DesiredCategory   

               ner= '\n'.join([str(elem) for elem in ner0])        ###########################  ners by space
               Category= '\n'.join([str(elem) for elem in category0]) 
               #print(ner0)
              #print(CategCategoryory)
               listsource.append(Source)
               listners.append(ner)
               listcategory.append(Category)
               listlink.append(Link)
               listdate.append(str(single_date))
              #----------------------------------
               copyDesiredNER=[]
               copyDesiredCategory=[]
               for m in range(len(DesiredNER)):
                 if str(DesiredNER[m]) not in copyDesiredNER:
                   copyDesiredNER.append(str(DesiredNER[m]))
                   copyDesiredCategory.append(str(DesiredCategory[m]))

                 #else:
                   #print("already found---",DesiredNER[m])
               if (len(copyDesiredNER)!=len(copyDesiredCategory)):
                 print("\n----------------Alert1----------------------")    
                 print("len of unique array ner  for article     :",len(copyDesiredNER))
                 print("len of unique array category for article :",len(copyDesiredCategory))
                 print("----------------------------------------------\n") 
               ref='/content/'
               Existflag = os.path.exists(ref)
               if not Existflag:
                  os.makedirs(ref)
                  file1=open(ref+'ner1.txt', 'w')
                  file2=open(ref+'category1.txt', 'w')
                  file1.close()
                  file2.close()

               #--------------------------------------------
               file1=open(ref+'ner1.txt', 'r')
               old=file1.readlines()
               file1.close()
               file1=open(ref+'ner1.txt', 'a')
               file2=open(ref+'category1.txt', 'a')

               for k in range(len(copyDesiredNER)):
                  if ("\n" in str(copyDesiredNER[k])):
                    temp=str(copyDesiredNER[k]);
                    temp1=temp.split(('\n'))
                    temp=""
                    if len(temp1) > 1: 
                      for t in temp1:
                        temp=temp+" "+t;
                    else:
                       temp=temp[0]; 
                  else:
                    temp=str(copyDesiredNER[k])+"\n"
                      #print('tttttttttttttttttt',type(temp))
                      #print('fffffffffffffff',type(old))
                    if temp.lower() not in str(old).lower():
                        file1.write(str(copyDesiredNER[k])+"\n")
                        file2.write(str(copyDesiredCategory[k])+"\n")
                
               file1.close()
               file2.close()
               file1=open(ref+'ner1.txt', 'r')
               w_ners=file1.readlines()
               file2=open(ref+'category1.txt', 'r')
               w_cats=file2.readlines()
               file1.close()
               file2.close()
               if (len(w_ners)!=len(w_cats)):
                print("\n-----------------Alert2-------------------")    
                print("Unique Ners total      :",len(w_ners))
                print("Unique category total  :",len(w_cats))
                print("-------------------------------------------\n")  

               #df2 = pd.read_csv("/content/drive/MyDrive/unique/ner.csv")
          
                #after finding ners store in a dictionary and store for future use 
          dict = {'Source':listsource,'Link':listlink,'NER': listners, 'Category': listcategory,'Date':listdate
               }  
          df = pd.DataFrame(dict) 
          Existflag = os.path.exists('/content/drive/MyDrive/data3/'+ nsite +'/')
          if not Existflag:
            os.makedirs('/content/drive/MyDrive/data3/'+ nsite +'/')
          with open('/content/drive/MyDrive/data3/'+ nsite +'/'+ str(single_date)+'.csv', 'a') as f:   # add to drive
           df.to_csv(f,header=f.tell()==0)
           print(nsite,' => ',i,"/",len(myFilesPaths))
           #print(nsite,' => ',str(single_date),"/",len(dates_folders))

ref1='/content/'
file1=open(ref1+'ner1.txt', 'w+')
file1.close()
file2=open(ref1+'category1.txt', 'w+')
file2.close()

start_date = date(2021,12,1)    #  start date from which treb=nds need to be calculated
end_date = date(2021,12,23)
scmp=NameEntityComputer()
xinhua=NameEntityComputer()
tass=NameEntityComputer()
sputnik=NameEntityComputer()
# dawn=NameEntityComputer()
# tribune=NameEntityComputer()
# nyt=NameEntityComputer()
# toi=NameEntityComputer()


scmp.helper('scmp',start_date,end_date) 
xinhua.helper('xinhua',start_date,end_date)
tass.helper('tass',start_date,end_date)    
sputnik.helper('sputnik',start_date,end_date)
# dawn.helper('dawn',start_date,end_date)      
# tribune.helper('tribune',start_date,end_date)
# nyt.helper('NYT',start_date,end_date)   
# toi.helper('toi',start_date,end_date)

fsfs

start_date = date(2021,3,14)    #  start date from which treb=nds need to be calculated
end_date = date(2021,11,1)
toi=NameEntityComputer()  #class object


nyt=NameEntityComputer()


dawn=NameEntityComputer()


tribune=NameEntityComputer()
 

tass=NameEntityComputer()  #class object


scmp=NameEntityComputer()


sputnik=NameEntityComputer()
 

xinhua=NameEntityComputer()


t1=threading.Thread(target=dawn.helper, args=('dawn',start_date,end_date, ))
t2=threading.Thread(target=nyt.helper, args=('NYT',start_date,end_date, ))
t3=threading.Thread(target=tribune.helper, args=('tribune',start_date,end_date, ))
t4=threading.Thread(target=toi.helper, args=('toi',start_date,end_date, ))

t5=threading.Thread(target=scmp.helper, args=('scmp',start_date,end_date, ))
t6=threading.Thread(target=tass.helper, args=('tass',start_date,end_date, ))
t7=threading.Thread(target=sputnik.helper, args=('sputnik',start_date,end_date, ))
t8=threading.Thread(target=xinhua.helper, args=('xinhua',start_date,end_date, ))

t1.start()
t2.start()
t3.start()
t4.start()
t5.start()
t6.start()
t7.start()
t8.start()

t1.join()
t2.join()
t3.join()
t4.join()
t5.join()
t6.join()
t7.join()
t8.join()

# start_date = date(2021,11,15)    #  start date from which treb=nds need to be calculated
# end_date = date(2021,12,1)
# toi=NameEntityComputer()
# t1=threading.Thread(target=toi.helper, args=('NYT',start_date,end_date, ))
# t1.start()
# t1.join()

kkkl

start_date = date(2021,11,18)    #  start date from which treb=nds need to be calculated
end_date = date(2021,12,1)
toi=NameEntityComputer()
t1=threading.Thread(target=toi.helper, args=('xinhua',start_date,end_date, ))
t1.start()
t1.join()

start_date = date(2021,11,6)    #  start date from which treb=nds need to be calculated
end_date = date(2021,12,1)
toi=NameEntityComputer()
toi.helper('scmp',start_date,end_date)
#t1=threading.Thread(target=toi.helper, args=('toi',start_date,end_date, ))
#t1.start()
#t1.join()

start_date = date(2021,11,17)    #  start date from which treb=nds need to be calculated
end_date = date(2021,12,1)
toi=NameEntityComputer()
t1=threading.Thread(target=toi.helper, args=('tass',start_date,end_date, ))
t1.start()
t1.join()

start_date = date(2021,11,11)    #  start date from which treb=nds need to be calculated
end_date = date(2021,12,1)
toi=NameEntityComputer()
t1=threading.Thread(target=toi.helper, args=('sputnik',start_date,end_date, ))
t1.start()
t1.join()

start_date = date(2021,11,15)    #  start date from which treb=nds need to be calculated
end_date = date(2021,12,1)
toi=NameEntityComputer()
t1=threading.Thread(target=toi.helper, args=('scmp',start_date,end_date, ))
t1.start()
t1.join()



start_date = date(2021,11,9)    #  start date from which treb=nds need to be calculated
end_date = date(2021,12,1)
toi=NameEntityComputer()
t1=threading.Thread(target=toi.helper, args=('dawn',start_date,end_date, ))
t1.start()
t1.join()







start_date = date(2021,11,1)    #  start date from which treb=nds need to be calculated
end_date = date(2021,11,15)
toi=NameEntityComputer()  #class object


nyt=NameEntityComputer()


dawn=NameEntityComputer()


tribune=NameEntityComputer()
 

tass=NameEntityComputer()  #class object


scmp=NameEntityComputer()


sputnik=NameEntityComputer()
 

xinhua=NameEntityComputer()


t1=threading.Thread(target=dawn.helper, args=('dawn',start_date,end_date, ))
t2=threading.Thread(target=nyt.helper, args=('NYT',start_date,end_date, ))
t3=threading.Thread(target=tribune.helper, args=('tribune',start_date,end_date, ))
t4=threading.Thread(target=toi.helper, args=('toi',start_date,end_date, ))

t5=threading.Thread(target=scmp.helper, args=('scmp',start_date,end_date, ))
t6=threading.Thread(target=tass.helper, args=('tass',start_date,end_date, ))
t7=threading.Thread(target=sputnik.helper, args=('sputnik',start_date,end_date, ))
t8=threading.Thread(target=xinhua.helper, args=('xinhua',start_date,end_date, ))

t1.start()
t2.start()
t3.start()
t4.start()
t5.start()
t6.start()
t7.start()
t8.start()

t1.join()
t2.join()
t3.join()
t4.join()
t5.join()
t6.join()
t7.join()
t8.join()

import pandas as pd

df = pd.read_csv("/content/drive/MyDrive/unique/ner.csv")


df1=df1["name"].str.lower()
print(df['name'][0])
if 'Imran khan' in df.values :
    print("\nThis value exists in Dataframe")
else :
    print("\nThis value does not exists in Dataframe")

import re
line="""al(){} ! is 2"""
line = re.sub('[!@#$"%^&*()+_=<>/?{}~`|]', '', line)
line